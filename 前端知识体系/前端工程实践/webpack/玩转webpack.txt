
第三章：webpack进阶用法（基础篇）

7.提取页面公共资源 /* todo */
基础库的分离
  思路：将react react-dom vue等基包库通过cdn引入，不打入bundle中。
  方法：使用html-webpack-externals-plugin
    new HtmlWebpackExternalsPlugin({
      externals: [
        {
          module: 'react',
          entry: 'https://cdn.bootcdn.net/ajax/libs/react/15.6.0/react.min.js',
          global: 'React'
        },
        {
          module: 'react-dom',
          entry: 'https://cdn.bootcdn.net/ajax/libs/react/15.6.0/react-dom.min.js',
          global: 'ReactDOM'
        }
      ]
    })
    然后在html中将react和react-dom依赖脚本引入进来。
  利用split-chunks-plugin进行公共脚本分离
    split-chunks-plugin是webpack4内置的功能非常强大的插件，做代码分割基本是离不开这个插件的，用来代替commons-chunk-plugin，
    optimization: {
      splitChunks: {
        chunks: "async",
        minSize: 30000, // 抽离的公共包最小的大小，单位是字节
        maxSize: 0, // 抽离的公共包最大的大小，单位是字节
        minChunks: 1, // 使用的次数超过这个就提取成公共的文件
        maxAsyncRequests: 5, // 
        maxInitialRequests: 3, // 同时请求的异步资源的次数
        automaticNameDelimiter: '~',
        name: true,
        cacheGroups: {
          vendors: {
            test: /[\\/]node_modules[\\/]/,
            priority: -10
          },
          default: {
            minChunks: 2,
            priority: -20,
            reuseExistingChunk: true
          }
        }
      }
    }
    可以看出来这个插件是很复杂的，也从侧面反映出这个插件的功能强大。
    chunks参数说明
      async：只异步引入的库进行分离（默认）
      initial：只同步引入的库进行分离
      all：所有引入的库进行分析（推荐）
    利用split-chunks-plugin分离基础包
      test：匹配出需要分离的包
      使用时还需要把vendors的chunk添加到HtmlWebpackPlugin的chunk里面
      optimization: {
        splitChunks: {
          cacheGroups: {
            commons: {
              test: /(react|react-dom)/,
              name: "vendors",
              chunks: "all"
            }
          }
        }
      }
    利用split-chunks-plugin分离页面公共文件
      optimization: {
        splitChunks: {
          minSize: 0,
          cacheGroups: {
            commons: {
              name: "commons",
              chunks: "all",
              minChunks: 2
            }
          }
        }
      }
  
8.Tree Shaking的使用和原理分析
Tree Shaking（摇树优化）
Tree Shaking在webpack4已经默认支持了，在生产环境mode: 'production'是默认开启的。
在.babelrc里设置modules: false即可
概念：一个模块可能有多个方法，Tree Shaking就是只把用到的方法打入bundle，没用到的方法会在uglify阶段被擦除掉。
使用Tree Shaking，写法必须是es6的语法，cjs的模块的方式不支持。
使用：production mode的情况下默认开启，在.babelrc里设置modules: false即可。
Tree Shaking原理 
  DCE(Elimination)，有下面三种情况：
    代码不会被执行，不可到达
      if () {
        console.log('这段代码永远不会执行')
      }
    代码执行的结果不会被用到
    代码只会影响死变量（只写不读），前面定义改变了这个变量，最后并没有用到这个变量
  Tree Shaking也是利用了DCE的这个特点，从而来分析，看看哪些代码是需要被删除掉的。
  代码擦除：Tree Shaking将没有用到的代码加一些注释来标记，在uglify阶段删除无用代码。

9.Scope Hoisting使用和原理分析 /* todo */
在webpack4里面很重要的一个特性。
没有开启Scope Hoisting的现象：
  构建之后的代码存在大量的闭包代码。对于每一个模块打包出来是会有一个函数的包裹。
会导致的问题：
  大量函数的闭包包裹代码，会导致导报出来的bundle.js文件体积增大（模块越多越明显）。
  由于是通过函数闭包的形式包裹代码，运行代码时创建的函数作用域就会变多，内存开销变大。
为什么webpack打包的时候，会打包出这么多函数包裹来把代码包裹起来呢，这就需要做下面的分析。
模块转换分析
  webpack会将模块转化成模块初始化函数，这里会做两件事情：
  1.把这个模块加一个包裹。
  2.将import代码转换成__webpack_require，export也会做相应的转换。
进一步分析webpack模块机制
  打包出来的是一个IIFE（匿名闭包）
  modules是一个数组，每一项是一个模块初始化函数，会传递给函数
  __webpack_require用来加载模块，返回module.exports
  通过WEBPACK_REQUIRE_MOTHOD(0)启动程序
对上面提到的包裹代码做优化
scope hoisting原理
  将所有模块的代码按照引用顺序放在一个函数作用域里面，然后适当的重命名一些变量以防止变量名冲突。
  对比：通过scope hoisting可以减少函数声明代码和内存开销。
scope hoisting使用
  webpack3里面需要手动的加一行代码
    new webpack.optimize.ModuleConcatenationPlugin()
  webpack4 mode为production默认开启
  必须是es6语法，cjs不支持

10.代码分割和动态import
前面介绍的split-chunks-plugin提取基础包和公共的内容，这个是初步的代码分割的内容。
这节介绍代码分割另外一个比较常用的手段，动态import或cjs里面的require.ensure语法
代码分割的意义
  对大的web应用而言，将所有的代码都放在一个文件中显然是不够有效的，特别是你的代码在一些情况下才会用到，首屏加载不会用到的。这
  时候我们针对首屏会打出一个js文件，对于其他的页面或tab切换的场景可以通过按需加载，也就是js懒加载的形式，它和懒加载图片是一样
  的道理，我们用到了这个脚本再加载它。这就是webpack里面提供的一个懒加载的功能，webpack将你的代码库分割成chunks（语块），当
  代码运行到需要它们的时候再进行加载。
适用场景：
  抽离相同代码到一个共享块
  脚本懒加载，用到的时候再加载，使得初始下载的代码更小
    commonjs：require.ensure
    es6：动态import（webpack比较推荐的一种方式，目前还没有原生支持，需要安装babel插件支持这种语法）
      import xxx from 'xxx' 是静态的，动态的是我们使用到的时候再import，动态的import功能和require比较像，可以通过逻辑
      按需加载，而不是要一开始就把这个模块加载进来。
      使用动态import：
        安装babel插件：
          npm i @babel/plugin-syntax-dynamic-import -D
        将这个插件添加到.babelrc配置文件的plugins中去
          {
            pulgins: ["@babel/plugin-syntax-dynamic-import"]
          }
        然后就可以在我们的代码中使用动态的import语法了。
          import('./text.js') // 返回的是promise对象
            .then(Text => {
              // Text就是import的这个文件export出去的内容
              console.log(Text)
            })
      代码分割的效果：
        使用了动态import的文件会分割出去一个js文件，当你代码用到的时候再异步的请求加载这个js文件。
      原理
        webpack使用jsonp的形式动态的添加一个<script>脚本进来。

11.在webpack中使用ESLint
eslint的必要性
  写js代码的时候将明显的问题及时的暴露出来，通过规范的一个检查，推荐使用eslint，eslint检查js是比较主流的做法。
行业里面优秀的eslint规范实践
  airbnb：eslint-config-airbnb eslint-config-airbnb-base
制定团队的eslint规范，遵循以下原则
  不重复造轮子，基于eslint:recommend配置去改进
  能够帮助发现代码错误的规则，全部开启 
  帮助保持团队的代码风格统一，而不是限制开发体验
eslint如何执行落地，常用的有两种方案
  1.和CI/CD系统集成
    把代码检查放在CI/CD的pipeline里面去 
    使用：
      本地开发阶段增加precommit钩子
      安装husky
        npm i husky -D
      增加npm script，通过lint-staged增量检查修改的文件，如果代码有语法问题会阻止你这次的提交
        "script": {
          "precommit": "lint-staged"
        },
        "lint-staged": {
          "linters": {
            "*.{js,scss}": ["eslint --fix", "git add"]
          }
        }
  2.和webpack等构建工具集成
    我们进行webpack构建的时候，如果遇见了eslint的语法问题，就直接中断构建，语法修改正确后才能构建成功。
    使用：
      比较适合新的项目，一开始就使用了eslint的项目。不适合老的项目去接入，因为这种方案，webpack构建的时候它会默认把所有的
      文件都会进行检查。
      使用eslint-loader，构建时检查js规范。
      module: {
        rules: [
          {
            test: /\.js$/,
            exclude: /node_modules/,
            use: {
              'babel-loader',
              'eslint-loader'
            }
          }
        ]
      }

12.webpack打包组件和基础库
webpack里面怎么去打包一个组件或一个库。
我们日常开发过程中，除了使用webpack去打包我们的业务项目之外，webpack还有其他的一些场景，比如通过webpack去打包一个组件，
去做server render，或者prerender等等场景。
对于打包组件或基础库，除了webpack，rollup更加适合打包组件和库，因为它打包相对webpack更加纯粹，使用更加简单。但是由于
webpack功能比较强大，使用webpack打包组件和库的场景还是很多的。
实际案例：实现一个大整数加法库的打包
  需要打包压缩版和非压缩版本。
  使用的时候支持AMD/CJS/ESM模块引入，也支持script标签方式引入。
库的目录结构和打包要求
  /dist
    large-number.js
    large-number.min.js
  webpack.config.js
  package.json
  index.js
  /src
    index.js
支持的模块使用方式
  支持ES module 
    import * as largeNumber from 'large-number'
    largeNumber.add('999', '1')
  支持CJS
    const largeNumber = require('large-number')
    largeNumber.add('999', '1')
  支持AMD
    require(['large-number'], function(large-number) {
      largeNumber.add('999', '1')
    })
  直接通过script引入，脚本发布到cdn上去
    <script src="https://unpkg.com/large-numer"></script>
    <script>
      largeNumber.add('999', '1')
    </script>
如何将库暴露出去
  打包组件和打包业务项目差别不大。打包组件的时候要针对output去额外设置一些内容，比如library libraryExport libraryTarget等
  library：指定库它暴露出去的库的名称，同时也可以通过全局变量的方式去引入到它。
  libraryTarget：支持库引入的方式，设置成umd就可以支持上述四种方式的引用。
  libraryExport：如果不设置成default，要通过largeNumber.default使用，不是很方便。
  module.exports = {
    entry: {
      'large-number': './src/index.js',
      'large-number.min': './src/index.js'
    },
    output: {
      filename: '[name].js',
      library: 'largeNumber',
      libraryTarget: 'umd',
      libraryExport: 'default'
    }
  }
如何只对.min压缩，通过include设置只压缩min.js结尾的文件
  optimization: {
    minimize: true,
    minimizer: [
      // 压缩js，遇到se6不会报错
      new TerserPlugin({
        include: /\.min\.js$/
      })
    ]
  }
设置入口文件
package.json的main字段为index.js
if (process.env.NODE_ENV === 'production') {
  module.exports = require('./dist/large-number.min.js')
} else {
  module.exports = require('./dist/large-number.js')
}
发布到npm上面去
  添加描述 "description": "大整数加法打包"
  增加npm script钩子，每次npm publish的时候会执行一下打包
    "scripts": {
      "test": "echo \"Error: no test specified\" && exit 1",
      "build": "webpack",
      "prepublish": "webpack"
    }
  登陆npm账号
    npm login
  发布
    npm publish

13.webpack实现SSR打包（上）/* todo */
14.webpack实现SSR打包（下）/* todo */
下节：在webpack里面怎么去做一个prerender这种场景，渲染骨架屏。/* todo 这个怎么没讲 */

15.优化构建时命令行的显示日志
构建的过程，命令行里面会有一大堆的信息打印出来，很多不需要开发者关注，开发者更加关注的是，构建是否成功，构建报错的信息，构建
warning的信息。对于构建成功的详细的信息，比如loader里输出的日志，插件的处理日志等并不是太需要关注的。
统计信息stats
  在webpack里用来输出统计的信息，通常可以分析一些构建速度或构建体积的时候，也可以到这个stats里分析一些数据出来。
  常见的stats有这些值。
    Preset	            Alternative	            Description
    "errors-only"           none              只在发生错误时输出
    "minimal"               none          只在发生错误或有新的编译时输出
    "none"                 false                  没有输出
    "normal"                true                  标准输出
    "verbose"               none                  全部输出
设置stats
  生产环境直接设置。
  开发环境如果用的是webpack-dev-server，就设置到这里面去。
命令行更加明显的提示信息
  使用friendly-errors-webpack-plugin，对于构建成功，警告，错误都有一个很明显的信息提示。
    success：构建成功的日志提示
    warning：构建警告的日志提示
    error：构建报错的日志提示
  有些框架或库会使用这个插件的
  stats设置成errors-only

16.构建异常和中断处理
在webpack里面怎么做错误的捕获和异常的处理。
如何判断构建是否成功？
  构建完之后，接下来要部署或做一些其他的操作比如代码的同步文件的同步等这些操作，这时候像CI/CD的系统或者发布系统它怎么知道这次
  构建是否成功呢。
  可以每次构建完之后输入一个 echo $? 获取错误码。如果错误码不为0的话，说明这次构建是失败的。也可以获取到error的信息。
webpack4之前构建失败不会抛出错误码。
webpack4给我们抛出了错误码，但是我们想针对异常的情况需要加额外的处理怎么做呢？
  1.每次捕获报错
  2.通过node.js中的process.exit规范去把错误码抛出来。这个规范也是尊从命令行里面的error
    0表示成功完成，回调函数中，err为null
    非0表示执行失败，回调函数中，err不为null，err.code就是传给exit的数字
如何主动捕获并处理构建错误？
  通过compiler这个对象，compiler在每次构建结束后会触发done这个hook，我们只要监听done这个hook，就可以对它进行额外的一些操作。
  比如数据上报相关的信息。错误信息可以通过stats获取到。
  plugins: [
    function() {
      this.hooks.done.tap('done', stats => {
        if (stats.compilation.errors && stats.compilation.errors.length && process.argv.indexOf('--watch') === -1) {
          console.log('build error')
          process.exit(1)
        }
      })
    }
  ]

第四章：编写可维护的webpack构建配置（进阶篇）
1.构建配置包设计
把之前的用法做到更加的通用，让我们其他的业务项目都能够用的上来，把构建包做到更加的通用。设计这个构建包的思路。
构建配置抽离成npm包的意义
  通用性
    业务开发者无需关注构建配置，创建好一个项目就可以马上使用把项目run起来，极大的提升开发效率
    统一团队构建脚本
  可维护性
    构建配置合理的拆分，做到更加的通用，后面维护也更加的方便，比如增加或修改一个新功能，能很方便的从构建包里找到相应的位置进行
    修改。如果把所有的配置放到一个文件里面，非常难改，改一个地方可能影响其他的环境配置。
    readme文档、ChangeLog文档，告诉开发者怎么使用这个构建包。
  构建质量
    冒烟测试、单元测试、测试覆盖率
    持续集成
构建配置管理的可选方案
  1.通过多个配置文件管理不同环境的构建，webpack --config参数进行控制
  2.将构建配置设计成一个库，用的时候直接使用这个库。比如hjs-webpack Neutrino webpack-blocks
  3.抽成一个工具进行管理，通过命令行工具来管理我们的构建配置。比如：create-react-app kyt nwb
  4.将所有的构建配置放到一个文件，通过--env参数控制分支选择。
构建配置包设计
  通过多个配置文件管理不同环境的webpack配置
    基础配置：webpack.base.js
    开发环境：webpack.dev.js
    生产环境：webpack.prod.js
    ssr环境：webpack.ssr.js
  抽离成一个npm包统一管理
    规范：要遵循这些规范 git commit 日志、readme、eslint规范、semver规范
    质量：需要我们的构建包有 冒烟测试、单元测试、测试覆盖率和CI 这些功能
    做好了规范和质量这两块，那基本上可以保证我们的构建配置它的长期的可维护性和质量保证。
  通过webpack merge组合配置
    比如我们的基础配置和开发配置有一些内容需要组合的情况下，如果使用数组的Array.prototype.concat或Object.assign这种组合
    起来会比较麻烦，webpack-merge的功能更加强大。
    const merge = require('webpack-merge')
    module.exports = merge(baseConfig, devConfig)

2.功能模块设计和目录结构
功能模块设计
  构建包功能设计
    基础配置：webpack.base.js
      资源解析
        解析es6
        解析react
        解析css
        解析less
        解析图片
        解析字体
      样式增强
        css前缀补齐
        css px转换成rem
      目录清理
      多页面打包
      命令行信息显示优化
      错误捕获和处理
      css提取成一个单独的文件
    开发阶段配置：webpack.dev.js
      代码热更新
        css热更新
        js热更新
      sourcemap
    生产阶段配置：webpack.prod.js
      代码压缩
      文件指纹
      tree shaking 
      scope hoisting
      速度优化
        基础包cdn
      体积优化
        代码分割
    ssr配置：webpack.ssr.js
      output的libraryTarget设置
      css解析ignore
目录结构设计
  目录结构的设计也是根据功能设计来制定的。
  test //测试代码，冒烟测试，单元测试
  lib // 包的源码
    webpack.base.js
    webpack.dev.js
    webpack.prod.js
    webpack.ssr.js
  README.md
  CHANGELOG.md
  .eslintrc.js
  package.json
  index.js // 入口文件

3.使用ESLint规范构建脚本
使用eslint-config-airbnb-base
eslint --fix 可以自动处理空格
.eslintrc.js
  module.exports = {
    "parser": "babel-eslint",
    "extends": "airbnb-base",
    "env": {
      "browser": true,
      "node": true
    }
  }

4.冒烟测试介绍和实际运用
冒烟测试是指对提交测试的软件在进行详细深入的测试之前而进行的预测试，就是软件开发人员在提交测试之前，会自己检查一下基本的功能
是否可用，这种预测试的主要目的是暴露导致软件需要重新发布的基本功能失效等严重问题。
构建配置包我们冒烟测试需要做什么事情呢？
  构建是否成功
  每次构建完成的build目录是否有内容输出
    是否有js css等静态资源文件
    是否有html文件
测试的这个步骤，如果每次发版之前，自己去找一个项目手动的去运行，这个是比较繁琐的
  所以我们也是通过一些测试工具去运行上面的步骤，每次发版之前运行一下npm run test，它会先把这个构建包进行webpack打包，看看
  是否有报错，同时生成一些产物，如果这两步都是ok的，那就说明我们这一次冒烟测试进行的是比较顺利的。
判断构建是否成功
  在事例项目里面运行构建，看看是否有报错。
  将我们编写的webpack配置传给webpack函数，webpack函数执行这个功能，执行完之后，在它的回调函数里面有一个err和stats，err
  是单次构建有没有报错，有报错说明我们这次构建是不成功的，没有报错说明这次构建没问题，没有问题我们可以把基本的一些统计信息输出
  出来，比如构建的速度，相关的构建资源列表等。
  const prodConfig = require('./webpack.prod.js')
  webpack(prodConfig, (err, stats) => {
    if (err) {
      console.error(err)
      process.exit(2)
    }
    console.log(stats.toString({
      colors: true,
      modules: false,
      children: false,
      chunks: false,
      chunkModules: false
    }))
  })
判断基本功能是否正常
  借助单元测试工具
  编写mocha测试用例
    是否有js css等静态资源文件
    是否有html文件
  判断有无这些文件的测试用例跑的没问题，那就说明我们的基本功能也是ok的。

5.单元测试和测试覆盖率
冒烟测试保证了构建包的基本功能可用，更加细节的部分怎么保证呢，这时候就需要单元测试。
市面上，比较流行的单元测试的方式。
  单纯的测试框架，需要断言库
    测试框架：mocha, ava
    断言库：.chai .should.js .expect .bsetter-assert
  集成框架，开箱即用
    jasmine jest
  极简API
编写单元测试用例
  技术选型：mocha + chai
  测试代码：describe it except
  测试命令：mocha add.test.js
  add.test.js 
    const expect = require('chai').expect
    const add = require('../src/add')
    describe('use expect: src/add.js', () => {
      it('add(1, 2) === 3', () => {
        expect(add(1, 2).to.equal(3))
      })
    })
单元测试接入
  1.安装mocha + chai
    npm i mocha chai -D
  2.新建test目录，并增加xxx.test.js测试文件
  3.在package.json中的scripts字段增加test命令
    "scripts": {
      "test": "./node_modules/.bin/_mocha"
    }
  4.执行测试命令
    npm run test
测试覆盖率
  推荐使用gotwarlost/istanbul
  安装npm i istanbul -D
  使用istanbul cover test.js

6.持续集成和Travis CI
每次发布版本之前都应该有持续集成的功能，看我们的的单元测试用例是否正常跑过，跑过的代码才能合入到主干里面来。
持续集成的作用
  优点：
    快速发现错误
      每次git commit的时候都会自动的去持续集成，如果这次提交对功能有影响，可以通过持续集成的方式快速的告诉你这次提交的代码
      是有问题的，你就可以及时的修复这个问题。
    防止分支大幅偏离主干
      有时主干处于快速更新的状态
    持续集成能让我们的产品快速迭代，同时保证质量
    核心措施是，代码集成到主干之前，必须通过自动化测试，只要有一个测试用例失败，就不能集成。
github最流行的CI
接入Travis CI
  1.https://trivis-ci.org/ 使用github账号登录
  2.在https://trivis-ci.org/account/repositories 为项目开启权限
  3.项目根目录下新增.travis.yml配置文件 
    每次git commit的时候会自动的触发CI的功能，它会运行这个配置文件中定义的脚本 
.travis.yml文件内容
  language: node_js
  sudo: false
  cache:
    apt: true
    directories:
      - node_modules
  node_js: stable # 设置相应的版本
  install:
    - npm install -D # 安装构建器依赖
    - cd ./test/template-project
    - npm install -D # 安装模版项目依赖
  script:
    -npm test
实际项目接入travis CI的流程
  1.在githb中创建一个项目
  2.在travis-ci中激活该项目，这时我们的项目就接入travis-ci了。
  3.clone项目
  4.把之前构建包的代码挪过来
  5.项目根目录下新增.travis.yml配置文件 
  6.上传代码

7.发布构建包到npm社区
发布npm 
先到npm搜索要发布的包名有没有被别人用到
添加用户：npm adduser
登录npm账户：npm login
升级版本：
  升级补丁版本号：npm version patch
  升级小版本号：npm version minor
  升级大版本号：npm version major
  升级版本前需要提交git
  运行相应的命令会自动的帮你更新对应的版本号。它会自动帮你git提交一次版本号的更新。
  每次发布版本之前需要打个git tag：git tap v1.0.1。运行npm version它也会自动的帮你打这个tag 
  提交远程：git push origin master
生成这个包当前版本的changelog
发布版本：npm publish

8.Git Commit规范和changelog生成
基础包良好的commit规范有助于我们后续维护代码
良好的git commit规范优势：
  加快code review的流程
  根据规范的git commit的元数据可以快速的生成changelog文档，这样就避免手动的编写changelog消耗的时间。
  后续维护者可以知道feature被修改的原因
技术方案
  git commit提交格式
    统一团队git commit日志标准，便于后续代码review和版本发布
    使用angular的git commit日志作为基本规范
      提交类型限制为：feat,fix,docs,style,refactor,pref,test,chore,revert等
      提交信息分为两部分，标题（首字母不大写，末尾不要标点）、主体内容（正常的描述信息即可）
    日志提交时友好的类型选择提示
      commitize工具
    不符合要求格式的日志拒绝提交的保障机制
      使用vilidate-commit-msg工具
      需要同时在客户端、git server hook做
    统一changelog文档信息生成
      使用conventional-changelog-cli工具
提交格式要求
<type>(<scope>): <subject>
<BLANK LINE>
<body>
<BLANK LINE>
<footer>
格式说明如下：
共有三块内容：commit的头部，body内容，提交的尾部
  头部：
    type: 代表某次提交的类型
      feat: 新增特性
      fix: 修改bug
      docs: 文档修改
      style: 代码格式修改，空格、缩进、逗号等，不改变代码逻辑
      refactor: 代码重构，没有增加新功能feature或修复bug
      pref: 优化相关，如性能提升，体验优化等
      test: 测试用例修改，包括单元测试，集成测试等
      chore: 改变构建流程，或增加依赖库、工具等
      revert: 回滚到上一个版本
    scope: 作用域, commit影响的范围, 比如: route, component, utils, build...
    subject: commit的概述, 目的的简短描述, 建议符合 50/72 formatting
  内容：
    正常情况下写这个头部就已经符合一个标注的git commit规范的要求。不过有时候某一次提交可能影响很大，或做的事情很多，这时通过
    subject还不能很好的描述这一次提交做的事情，这时候可以在body里面分为几行去写，做了什么事情都可以详细的写在这里。
    body: commit 具体修改内容, 可以分为多行, 建议符合 50/72 formatting
  尾部：
    比如这次提交是修复了一个bug，可以贴上bug单的链接。或者修复一个issue，可以贴上issue的链接，把issue close掉。
    footer: 一些备注, 通常是 BREAKING CHANGE 或修复的 bug 的链接。
有这个规范还是不够的。
本地开发阶段增加precommit钩子
  对于git commit的信息也是需要通过一个工具来让git commit的规则能够很好的运作起来。
  安装husky
    npm i husky -D
  通过commitmsg钩子校验信息
    npm i vilidate-commit-msg conventional-changelog-cli -D
    "scripts": {
      "commitmsg": "vilidate-commit-msg",
      "changelog": "conventional-changelog -p angular -i CHANGELOG.md -s -r 0"
    }
    vilidate-commit-msg也是尊从angularjs提交规范
    每次git commit的时候，就会通过vilidate-commit-msg去检查这一次提交git的格式，如果是符合规范的，它就会允许你提交上去，
    不符合规范，就会提交失败。
    每次发布版本的时候可以运行changelog这个命令，可以很方便的生成一个changelog文档出来，这个版本信息就会全部的生成出来，包
    括两块内容，一个是bugfix，对应于fix；一个是feature，对应于feat。

9.语义化版本（Semantic Versioning）规范格式
开源项目版本信息案例（react）
  软件的版本通常由三位组成，形如：X.Y.Z
  版本是严格递增的，此处是：16.2.0 -> 16.3.0 -> 16.3.1
  在发布重要版本时，可以发布alpha，beta，rc等先行版本
遵守semver规范的优势
  semver规范是github提出来，当时也是为了解决软件开发领域里面依赖地狱的问题，主要是用来规范依赖的软件包，在日常的开发过程中，
  会依赖各种各样的依赖，这个依赖它也会依赖其他的依赖，这是就很容易形成一个依赖地狱，如果一旦依赖的版本号，没有一个很好的规范，
  很容易出现一些循环依赖，或者依赖之间会有一些冲突，尊从semver这个规范就能避免这个问题。
  优势：
    避免出现循环依赖
    依赖冲入减少
语义化版本（Semantic Versioning）规范格式
  主版本号：当你做了不兼容的API修改
  次版本号：当你做了向下兼容的功能性新增
  修订号：当你做了向下兼容的问题修复
先行版本号
  先行版本号可以作为发布正式版之前的版本，格式是在修订版本号后面加上一个连接号（-），再加上一连串以点（.）分割的标识符，标识符
  可以由英文数字和连接号（[0-9A-Za-z-]）组成。
  alpha：是内部测试版，一般不向外发布，会有很多bug。一般只有测试人员使用。
  beta：是外部小范围的测试版，这个阶段的版本会一直加入新的功能。在alhpa版之后推出。
  rc：Release Candidate，公测，系统平台上就是发行候选版本。rc版不会再加入新的功能，主要着重于除错。

第五章：webpack构建速度和体积优化策略
在webpack里面怎么分析构建速度和构建体积
1.初级分析：使用webpack内置的stats
stats：构建的统计信息
  利用webpack内置的stats对象
    它可以帮我们分析基本的一些信息，比如构建总共的时间，构建资源的大小
    package.json中使用stats
      指定输出的是一个json对象，生成一个json文件
      "scripts": {
        "build:stats": "webpack --config webpack.prod.js --json > stats.json"
      }
  node.js中使用
    const webpack = require('webpack')
    const config = require('./webpack.config.js')('production')
    webpack(config, (err, stats) => {
      if (err) {
        return console.error(err)
      }
      if (stats.hasErrors()) {
        return console.error(stats.toString('errors-only'))
      }
      console.log(stats)
    })
  这两种方式颗粒度太粗，看不出问题所在。想要分析实际的问题，比如哪个组件比较大，哪个loader耗的时间比较长，是无法很好的分析出来的。

2.速度分析：使用speed-measure-webpack-plugin
更好的分析webpack构建的速度，怎么找出构建速度问题所在。
使用speed-measure-webpack-plugin
  可以看到每个loader和插件执行耗时，就可以重点的关注耗时较长的loader或插件，针对这些做优化
  const SpeedMeatureWebpackPlugin = require('speed-measure-webpack-plugin')
  const smp = new SpeedMeatureWebpackPlugin()
  const webpackConfig = smp.wrap({
    plugins: [
      new MyPlugin(),
      new MyOtherPlugin()
    ]
  })
速度分析插件作用
  分析整个打包总耗时
  每个loader和插件的耗时情况

3.体积分析：使用webpack-bundle-analyzer
更好的分析项目打包出来的体积的问题所在
使用webpack-bundle-analyzer分析体积
  我们发现打包出来的体积很大，就可以利用这个工具来分析项目的问题出现在哪里。
  它可以把我们的项目打包出来的文件会进行一个分析，能很方便的看出体积的大小。面积越大体积越大，我们可以重点关注这些进行优化。
  const BundleAnalyzerPlugin = require('webpack-bundle-analyzer').BundleAnalyzerPlugin
  plugins: [
    new BundleAnalyzerPlugin()
  ]
  构建完成后会在8888端口展示体积大小
可以分析哪些问题
  可以很好的分析依赖的第三方模块文件的大小
  也可以分析出我们自己写的业务的组件代码图片大小，针对大的js可以做js的按需加载等优化操作。
增加babel-polyfill试验大的第三方模块的情况

4.使用高版本的webpack和Node.js
在webpack里做速度的优化
使用高版本的wepback和node.js
  在软件这一块，性能往往不是最大的问题，软件不断的迭代过程中，可以不断的提升这个性能，对于构建而言同样是适用的，所以推荐采用
  高版本的webpack和node.js。
使用webpack4：优化原因
  V8带来的优化，V8 6.0的版本带来了大量的优化，很多对原生方法的优化（for of代替forEach、Map和Set代替Object、includes代替indexOf）
  默认使用更快的md4的 hash算法
  webpacks AST可以直接从loader传递给AST，减少解析时间
  使用字符串的方法替代正则表达式
高版本的node.js对原生的js API或js的数据结构是有做一些优化的，因此推荐采用更高版本的node.js
  测试脚本
    验证高版本node.js比低版本node.js性能更快，针对相同的api、相同的代码做比较
      map-performance.js 
    includes和indexOf的性能差异
      compare-includes-indexOf.js

5.多进程/多实例构建
多进程/多实例构建：资源并行解析可选方案
  HappyPack
  thread-loader
  parallel-webpack
多进程/多实例：使用HappyPack解析资源
  原理：每次webpack解析一个模块，HappyPack会将它及它的依赖分配给worker线程中。
  每次webpack解析一个模块，一个进程webpack自身去解析这个模块。HappyPack会将这个模块进行一个划分，比如有多个模块，在
  webpack compiler run方法之后，然后到达HappyPack，它会做一些初始化，创建一个线程池，线程池会将构建任务里面的模块进行分配
  ，比如会将某个模块以及它的依赖分配给HappyPack其中的一个线程，以此类推，那么一个HappyPack的线程池可能会包括多个线程，这些
  线程会各自的处理这些模块以及它的依赖。处理完成之后，会有一个通信的过程，会将处理好的资源传输给HappyPack的主进程，完成整个构
  建的过程。
  plugins: [
    new HappyPack({
      id: 'jsx',
      threads: 4,
      loaders: ['babel-loader']
    }),
    new HappyPack({
      id: 'styles',
      threads: 2,
      loaders: ['style-loader', 'css-loader', 'less-loader']
    })
  ]
多进程/多实例：使用thread-loader解析资源
  webpack4.0原生的提供了thread-loader这个模块，它可以很好的替换HappyPack，来做多进程/多实例的工作。
  原理：跟HappyPack是差不多的。每次webpack解析一个模块，thread-loader会将它及它的依赖分配给worker线程中。
  module: {
    rules: [
      {
        test: /\.js$/,
        use: [
          {
            loader: 'thread-loader',
            options: {
              workers: 3
            }
          },
          'babel-loader'
        ]
      }
    ]
  }
  在我们的loader之前放上thread-loader，做一系列的解析，最后会通过thread-loader进行处理。

6.多进程/多实例并行压缩代码
多进程/多实例：并行压缩
上节提到在构建的时候，可以对模块的解析采用多进程多实例的方式去做。同样的，在代码解析完成之后，在做最后的代码输出之前，它有个压缩
阶段，对于代码压缩我们也是可以通过同样的思路，就是通过多进程多实例的并行的压缩代码，来达到我们优化构建速度的目的。
方法一：使用parallel-uglify-plugin插件
  plugins: [
    new ParallelUglifyPluging({
      uglifyJS: {
        output: {
          beautify: false,
          comments: false
        },
        compress: {
          warning: false,
          drop_console: true,
          collapse_vars: true,
          reduce_vars: true
        }
      }
    })
  ]
方法二：uglifyjs-webpack-plugin开启parallel参数（webpack3推荐采用的插件）（不支持es6代码的压缩）
  plugins: [
    new UglifyjsWebpackPlugin({
      uglifyOptions: {
        warnings: false,
        parse: {},
        compress: {},
        mangle: true,
        output: null,
        tiplevel: false,
        nameCache: null,
        ie8: false,
        keep_fnames: false
      },
      parallel: true
    })
  ]
方法三：terser-webpack-plugin开启parallel参数（webpack4默认使用的）（支持es6代码的压缩）
  module.exports = {
    optimization: {
      minimize: true,
      minimizer: [
        new TerserPlugin({
          parallel: true
        })
      ]
    }
  }

7.进一步分包：预编译资源模块
分包：设置Externals（第三章讲过的）
  思路：将react, react-dom基础包通过cdn引入，不打入bundle中。
  方法：使用html-webpack-externals-plugin
  缺点：一个基础库需要指定一个cdn，实际的项目中有很多包，需要引入的script标签太多 。
通过split-chunks-plugin插件分离基础包，它每次还是会对基础包进行分析。
分包来说，更好的方式就是
进一步分包：预编译资源模块
  思路：将react、react-dom、redux、react-redux基础包和业务基础包打包成一个文件。
  方法：使用webpack里面官方内置的插件DLLPlugin进行分包，DLLReferencePlugin对manifest.json引用，这个文件是对分离出来
  的包的描述。然后我们在实际的webpack配置里面可以通过DLLReferencePlugin去引用通过DLLPlugin分离出来的包，引用的时候应用
  manifest.json就可以了，引用后它就会自动的去关联DLLPlugin里面的包。
  使用DLLPlugin进行分包
    需要创建一个单独的构建配置文件，一般会命名为webpack.ddl.js，DLLPlugin也会提高打包的速度。
  使用DLLReferencePlugin引用manifest.json
    在webpack.config.js中引入
      module.exports = {
        plugins: [
          new webpack.DLLReferencePlugin({
            manifest: require('./build/library/manifest.json')
          })
        ]
      }

8.充分利用缓存提升二次构建速度
缓存
目的：提升二次构建速度
缓存思路：
  babel-loader开启缓存
  terser-webpack-plugin开启缓存
  使用cache-loader或者hard-source-webpack-plugin
    针对模块的缓存的开启
有缓存的话node_modules下面会有一个cache目录

9.缩小构建目标
缩小构建目标
  目的：尽可能的减少构建模块
  比如babel-loader不解析node_modules
    module: {
      rules: [
        {
          test: /\.js$/,
          use: 'babel-loader',
          exclude: 'node_modules'
        }
      ]
    }
减少文件搜索范围  
  优化resolve.modules配置（减少模块搜索层级）
    resolve.modules是模块解析的过程，webpack解析时，模块的查找过程和nodejs的模块查找是比较类似的，会从当前的项目找，没
    找到会去找node_modules。会依次去子目录找模块是否存在。
  优化resolve.mainFields配置
    找入口文件的时候，它会根据package.json里面的main字段查找，因为我们发布到npm的组件的package.json会遵守一定的规范，
    都会有main这个字段，我们可以设置查找的时候直接读取main这个字段，这样也减少一些不必要的分析的过程。比如package.json
    里面没有这个main，那它再去读取根项目下的index.js，没有再去找lib下面的index.js，这就是它默认的查找过程，我们这里把
    这个默认的查找过程链路做一个优化，我们只找package.json中main字段指定的入口文件。
  优化resolve.extensions配置
    模块路径的查找，比如import一个文件，没有写后缀，webpack会先去找.js，没有会找.json，默认情况下webpack只支持js和json
    的读取。extensions数组里可以再设置其他的文件，如.jsx .vue .ts等。不过这个数组里面的内容越多的话，查找消耗的时间也会
    越多，因此我们可以缩小extensions查找的范围，比如只设置查找.js，其他文件需要你写的时候写全文件后缀。避免webpack做不必要
    的查找。
  合理使用alias
    别名，简短的缩写。比如模块的路径，我们找react，它可能找了一圈，最后肯定是会找到node_modules里面去，它会经历一系列的
    查找过程，我们可以把这一系列的过程直接给它写好，告诉它比如你遇到了react，就直接从指定的这个路径去找。这个也大大的缩短
    了查找的时间。
  module.exports = {
    // 子模块的查找策略
    resolve: {
      alias: {
        'react': path.resolve(__dirname, './node_modules/react/umd/react.production.min.js'),
        'react-dom': path.resolve(__dirname, './node_modules/react-dom/umd/react-dom.production.min.js')
      },
      modules: [path.resolve(__dirname, 'node_modules')],
      extensions: ['.js'],
      mainFields: ['main']
    }
  }

10.使用Tree Shaking擦除无用的JavaScript和CSS
无用的css如何删除掉？
  PurifyCSS：遍历代码，识别已经用到的css class
  uncss：要求HTML需要通过jsdom加载，所有的样式通过PostCSS解析，通过document.querySelector来识别在html文件里面不存在的
         选择器。
在webpack中如何使用PurifyCSS？
  使用purgecss-webpack-plugin，它不能独立的去使用，而是需要提取css为一个文件后才能使用。在webpack4里面需要和
  mini-css-extract-plugin配合使用，在webpack3里面需要和extract-text-webpack-plugin配合使用。
  new PurgecssWebpackPlugin({
    paths: 
  })

11.使用webpack进行图片压缩
图片资源相对是较大的，我们可以通过在线工具手动进行图片的批量压缩。构建工具一部分的职责就是将平时我们手动完成的事做成自动化。
图片压缩
  要求：基于node库的imagemin或者tinypng API做图片压缩。
  使用：配置image-webpack-loader
imagemin的优点分析
  有很多定制的选项
  可以引入更多第三方优化插件，例如pngquant
  可以处理多种图片格式
imagemin的压缩原理
https://unsplash.com/ 无版图片库

12.使用动态Polyfill服务
构建体积优化：动态polyfill
方案
  babel-polyfill
  babel-plugin-transform-runtime
  自己写polyfill
  polyfil service
polyfil service原理
  识别ua，下发不同的polyfill
使用polyfil service
  polyfill.io官方提供的服务
    https://polyfill.io/v3/polyfill.min.js
  基于官方自建polyfill服务
    //huayang.qq.com/polyfill/v3/polyfill.min.js?unknown=polyfill&features=Promise,Map,Set
体积优化策略总结：
  Scope Hoisting
  Tree Shaking
  公共资源分离
  图片压缩
  动态polyfill

第六章：通过源代码掌握webpack打包原理
1.webpack启动过程分析
开始：从webpack命令行说起
  通过npm scripts运行webpack
    开发环境：npm run dev
    生产环境：npm run build
  通过webpack命令直接运行
    webpack entry.js bundle.js
查找webpack入口文件
  在命令行输入命令后，npm会让命令行工具进入node_modules/.bin目录，运行一个命令，如果是全局安装这个包，linux会从
  user/local/bin这个目录去找，局部安装会在当前项目目录的node_modules/.bin目录去找，查找是否存在webpack.sh或
  webpack.cmd文件。如果存在，就执行，不存在，就抛出错误。
  实际的入口文件是：node_modules/webpack/bin/webpack.js
  局部安装，想再node_modules/.bin下面有命令，必须通过package.json中的bin字段进行指定。
  因此启动的过程最终会进入到webpack.js，执行里面的代码。
分析webpack的入口文件：webpack.js
  process.exitCode = 0 // 默认exitCode是0，代表webpack运行的时候是正常的执行返回。中间报错会修改exitCode，并抛出错误。
  const runCommand = (command, args) => {} // 运行某个命令
  const isInstalled = packageName => {}; // 判断某个包是否安装
  const CLIs = []; // webpack可用的CLI：webpack-cli和webpack-command
  const installedClis = CLIs.filter(cli => cli.installed); // 判断两个cli是否安装了
  if (installedClis.length === 0) { // 根据cli安装的数量进行处理
  } else if (installedClis.length === 1) {
  } else {
  }
启动后的结果
  webpack最终找到webpack-cli(或webpack-command)这个npm包，并且执行cli

2.webpack-cli源码阅读
webpack-cli做的事情
  引入yargs，对命令行进行定制。
  分析命令行参数，对各个参数进行转换，组成编译配置项。
  引用webpack，根据配置项进行编译和构建。
从NON_COMPILATION_CMD分析出不需要编译的命令
  webpack-cli处理不需要经过编译的命令，就是不需要实例化webpack的
NON_COMPILATION_ARGS
  webpack-cli提供的不需要编译的命令
  const NON_COMPILATION_ARGS = [
    "init",              // 创建一份webpack配置文件
    "migrate",           // 运行webpack版本迁移
    "add",               // 往webpack配置文件中增加属性
    "remove",            // 往webpack配置文件中删除属性
    "serve",             // 运行webpack-serve
    "generate-loader",   // 生成webpack loader代码
    "generate-plugin",   // 生成webpack plugin代码
    "info"               // 返回与本地环境相关的一些信息
  ];
命令行工具包yargs介绍
  提供命令和分组参数
  动态生成help帮助信息
webpack-cli使用args分析
  参数分组（config/config-args.js），将命令划分为9类：
    Config options: 配置相关参数（文件名称，运行环境等）
    Basic options: 基础参数（entry设置、debug模式设置、watch监听设置、devtool设置）
    Module options: 模块参数，给loader设置扩展
    Output options: 输出设置（输出路径，输出文件名称）
    Advanced options: 高级用法（记录设置、缓存设置、监听频率、bail等）
    Resolving options: 解析参数（alias和解析的文件后缀设置）
    Optimizing options: 优化参数
    Stats options: 统计参数
    options: 通用参数（帮助命令、版本信息等）
options变量
  将命令行或webpack.config.js配置文件的配置解析出来组装成为webpack可识别的配置到options里面。
processOptions(options)函数
  outputOptions根options类似
实例化一个webpack
  webpack = require('webpack')
  compiler = webpack(options)
  new Plugin({
    option: true
  }).apply(compiler)
webpack-cli执行结果
  webpack-cli对配置文件和命令行参数进行转换，最终生成配置选项参数options和outputOptions。
  最终会根据配置参数实例化webpack对象，然后根据一些参数，如有没有--watch，有的话通过监听的方式去运行webpack，
  compiler.watch()没有的话直接运行webpack，compiler.run()。最后执行整个构建流程。

3.Tapable插件架构与Hooks设计
webpack的本质
  webpack可以将其理解成一种基于事件流的编程范例，一系列的插件运行。内部是由各种各样的插件，插件会监听compiler和compilation
  上面定义的关键的事件节点。
webpack里最核心的对象compiler和compilation都是继承自Tapable
  class Compiler extends Tapable {
    //...
  }
  class Compilation extends Tapable {
    //...
  }
Tapable是什么
  Tapable是一个类似于node.js的EventEmitter的库，主要是控制钩子函数的发布与订阅，控制着webpack的插件系统。
  Tapable库暴露了很多Hook(钩子)类，为插件提供挂载的钩子。每个钩子代表一个关键的事件节点，在插件中监听钩子，在不同的阶段做不
  同的事情。
  钩子：两类，同步钩子和异步钩子
  const {
    SyncHook,                   // 同步钩子
    SyncBailHook,               // 同步熔断钩子，遇到return直接返回
    SyncWaterfallHook,          // 同步流水钩子，执行结果可以传递给下一个插件
    SyncLoopHook,               // 同步循环钩子
    AsyncParallelHook,          // 异步并发钩子
    AsyncParallelBailHook,      // 异步并发熔断钩子
    AsyncSeriesHook,            // 异步串行钩子 
    AsyncSeriesBailHook,        // 异步串行熔断钩子
    AsyncSeriesWaterfallHook,   // 异步串行流水钩子
  } = require("tapable")
  Tapable hooks类型
    Hook           所有钩子的后缀
    Waterfall      同步方法，它会传值给下一个函数
    Bail           熔断：当函数有任何返回值，就会在当前执行函数停止
    Loop           监听函数返回true表示继续循环，返回undefined表示结束循环
    Sync           同步方法
    AsyncSeries    异步串行钩子
    AsyncParallel  异步并行执行钩子
  Tapable的使用 - new Hook新建钩子
    Tapable暴露出来的都是类方法，new一个类方法获得我们需要的钩子
    class接受数组参数options，非必传。类方法会根据传参，接受同样数量的参数。
    const hook1 = new SyncHook(['arg1', 'arg2', 'arg3'])
  Tapable的使用 - 钩子的绑定与执行
    Tapable提供了同步&异步绑定钩子的方法，并且它们都有绑定事件和执行事件对应的方法。
    Async*                           Sync*                  
    绑定：tapAsync/tapPromise/tap     绑定：tap
    执行：callAsync/promise           执行：call
  Tapable的使用 - hook基本用法示例
    const hook1 = new SyncHook(['arg1', 'arg2', 'arg3'])
    // 绑定事件到webpack事件流
    hook1.tap('hook1', (arg1, arg2, arg3) => {console.log(arg1, arg2, arg3)})
    // 执行绑定的事件
    hook1.call(1, 2, 3)
  Tapable的使用 - 实际例子演示
    定义一个Car方法，在内部hooks上新建钩子。分别是同步钩子accelerate、break（accelerate接收一个参数）、异步钩子
    calculateRoutes。
    使用钩子对应的绑定和执行方法。
    calculateRoutes使用tapPromise可以返回一个promise对象。

4.Tapable是如何和webpack进行关联起来的？
compiler和compilation上面做hooks的调用。
Tapable是事件的机制，webpack插件机制都是基于Tapable的钩子。
插件有个apply方法，接收一个compiler参数。
插件上面做事件的监听。

5.webpack流程篇：准备阶段
6.webpack流程篇：模块构建和chunk生成阶段
7.webpack流程篇：文件生成
8.动手编写一个简易的webpack(上)
9.动手编写一个简易的webpack(下)

第七章：编写loader和插件

第八章：React全家桶和webpack开发商城项目
