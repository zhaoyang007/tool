第四章：编写可维护的webpack构建配置（进阶篇）
1.构建配置包设计
把之前的用法做到更加的通用，让我们其他的业务项目都能够用的上来，把构建包做到更加的通用。设计这个构建包的思路。
构建配置抽离成npm包的意义
  通用性
    业务开发者无需关注构建配置，创建好一个项目就可以马上使用把项目run起来，极大的提升开发效率
    统一团队构建脚本
  可维护性
    构建配置合理的拆分，做到更加的通用，后面维护也更加的方便，比如增加或修改一个新功能，能很方便的从构建包里找到相应的位置进行
    修改。如果把所有的配置放到一个文件里面，非常难改，改一个地方可能影响其他的环境配置。
    readme文档、ChangeLog文档，告诉开发者怎么使用这个构建包。
  构建质量
    冒烟测试、单元测试、测试覆盖率
    持续集成
构建配置管理的可选方案
  1.通过多个配置文件管理不同环境的构建，webpack --config参数进行控制
  2.将构建配置设计成一个库，用的时候直接使用这个库。比如hjs-webpack Neutrino webpack-blocks
  3.抽成一个工具进行管理，通过命令行工具来管理我们的构建配置。比如：create-react-app kyt nwb
  4.将所有的构建配置放到一个文件，通过--env参数控制分支选择。
构建配置包设计
  通过多个配置文件管理不同环境的webpack配置
    基础配置：webpack.base.js
    开发环境：webpack.dev.js
    生产环境：webpack.prod.js
    ssr环境：webpack.ssr.js
  抽离成一个npm包统一管理
    规范：要遵循这些规范 git commit 日志、readme、eslint规范、semver规范
    质量：需要我们的构建包有 冒烟测试、单元测试、测试覆盖率和CI 这些功能
    做好了规范和质量这两块，那基本上可以保证我们的构建配置它的长期的可维护性和质量保证。
  通过webpack merge组合配置
    比如我们的基础配置和开发配置有一些内容需要组合的情况下，如果使用数组的Array.prototype.concat或Object.assign这种组合
    起来会比较麻烦，webpack-merge的功能更加强大。
    const merge = require('webpack-merge')
    module.exports = merge(baseConfig, devConfig)

2.功能模块设计和目录结构
功能模块设计
  构建包功能设计
    基础配置：webpack.base.js
      资源解析
        解析es6
        解析react
        解析css
        解析less
        解析图片
        解析字体
      样式增强
        css前缀补齐
        css px转换成rem
      目录清理
      多页面打包
      命令行信息显示优化
      错误捕获和处理
      css提取成一个单独的文件
    开发阶段配置：webpack.dev.js
      代码热更新
        css热更新
        js热更新
      sourcemap
    生产阶段配置：webpack.prod.js
      代码压缩
      文件指纹
      tree shaking 
      scope hoisting
      速度优化
        基础包cdn
      体积优化
        代码分割
    ssr配置：webpack.ssr.js
      output的libraryTarget设置
      css解析ignore
目录结构设计
  目录结构的设计也是根据功能设计来制定的。
  test //测试代码，冒烟测试，单元测试
  lib // 包的源码
    webpack.base.js
    webpack.dev.js
    webpack.prod.js
    webpack.ssr.js
  README.md
  CHANGELOG.md
  .eslintrc.js
  package.json
  index.js // 入口文件

3.使用ESLint规范构建脚本
使用eslint-config-airbnb-base
eslint --fix 可以自动处理空格
.eslintrc.js
  module.exports = {
    "parser": "babel-eslint",
    "extends": "airbnb-base",
    "env": {
      "browser": true,
      "node": true
    }
  }

4.冒烟测试介绍和实际运用
冒烟测试是指对提交测试的软件在进行详细深入的测试之前而进行的预测试，就是软件开发人员在提交测试之前，会自己检查一下基本的功能
是否可用，这种预测试的主要目的是暴露导致软件需要重新发布的基本功能失效等严重问题。
构建配置包我们冒烟测试需要做什么事情呢？
  构建是否成功
  每次构建完成的build目录是否有内容输出
    是否有js css等静态资源文件
    是否有html文件
测试的这个步骤，如果每次发版之前，自己去找一个项目手动的去运行，这个是比较繁琐的
  所以我们也是通过一些测试工具去运行上面的步骤，每次发版之前运行一下npm run test，它会先把这个构建包进行webpack打包，看看
  是否有报错，同时生成一些产物，如果这两步都是ok的，那就说明我们这一次冒烟测试进行的是比较顺利的。
判断构建是否成功
  在事例项目里面运行构建，看看是否有报错。
  将我们编写的webpack配置传给webpack函数，webpack函数执行这个功能，执行完之后，在它的回调函数里面有一个err和stats，err
  是单次构建有没有报错，有报错说明我们这次构建是不成功的，没有报错说明这次构建没问题，没有问题我们可以把基本的一些统计信息输出
  出来，比如构建的速度，相关的构建资源列表等。
  const prodConfig = require('./webpack.prod.js')
  webpack(prodConfig, (err, stats) => {
    if (err) {
      console.error(err)
      process.exit(2)
    }
    console.log(stats.toString({
      colors: true,
      modules: false,
      children: false,
      chunks: false,
      chunkModules: false
    }))
  })
判断基本功能是否正常
  借助单元测试工具
  编写mocha测试用例
    是否有js css等静态资源文件
    是否有html文件
  判断有无这些文件的测试用例跑的没问题，那就说明我们的基本功能也是ok的。

5.单元测试和测试覆盖率
冒烟测试保证了构建包的基本功能可用，更加细节的部分怎么保证呢，这时候就需要单元测试。
市面上，比较流行的单元测试的方式。
  单纯的测试框架，需要断言库
    测试框架：mocha, ava
    断言库：.chai .should.js .expect .bsetter-assert
  集成框架，开箱即用
    jasmine jest
  极简API
编写单元测试用例
  技术选型：mocha + chai
  测试代码：describe it except
  测试命令：mocha add.test.js
  add.test.js 
    const expect = require('chai').expect
    const add = require('../src/add')
    describe('use expect: src/add.js', () => {
      it('add(1, 2) === 3', () => {
        expect(add(1, 2).to.equal(3))
      })
    })
单元测试接入
  1.安装mocha + chai
    npm i mocha chai -D
  2.新建test目录，并增加xxx.test.js测试文件
  3.在package.json中的scripts字段增加test命令
    "scripts": {
      "test": "./node_modules/.bin/_mocha"
    }
  4.执行测试命令
    npm run test
测试覆盖率
  推荐使用gotwarlost/istanbul
  安装npm i istanbul -D
  使用istanbul cover test.js

6.持续集成和Travis CI
每次发布版本之前都应该有持续集成的功能，看我们的的单元测试用例是否正常跑过，跑过的代码才能合入到主干里面来。
持续集成的作用
  优点：
    快速发现错误
      每次git commit的时候都会自动的去持续集成，如果这次提交对功能有影响，可以通过持续集成的方式快速的告诉你这次提交的代码
      是有问题的，你就可以及时的修复这个问题。
    防止分支大幅偏离主干
      有时主干处于快速更新的状态
    持续集成能让我们的产品快速迭代，同时保证质量
    核心措施是，代码集成到主干之前，必须通过自动化测试，只要有一个测试用例失败，就不能集成。
github最流行的CI
接入Travis CI
  1.https://trivis-ci.org/ 使用github账号登录
  2.在https://trivis-ci.org/account/repositories 为项目开启权限
  3.项目根目录下新增.travis.yml配置文件 
    每次git commit的时候会自动的触发CI的功能，它会运行这个配置文件中定义的脚本 
.travis.yml文件内容
  language: node_js
  sudo: false
  cache:
    apt: true
    directories:
      - node_modules
  node_js: stable # 设置相应的版本
  install:
    - npm install -D # 安装构建器依赖
    - cd ./test/template-project
    - npm install -D # 安装模版项目依赖
  script:
    -npm test
实际项目接入travis CI的流程
  1.在githb中创建一个项目
  2.在travis-ci中激活该项目，这时我们的项目就接入travis-ci了。
  3.clone项目
  4.把之前构建包的代码挪过来
  5.项目根目录下新增.travis.yml配置文件 
  6.上传代码

7.发布构建包到npm社区
发布npm 
先到npm搜索要发布的包名有没有被别人用到
添加用户：npm adduser
登录npm账户：npm login
升级版本：
  升级补丁版本号：npm version patch
  升级小版本号：npm version minor
  升级大版本号：npm version major
  升级版本前需要提交git
  运行相应的命令会自动的帮你更新对应的版本号。它会自动帮你git提交一次版本号的更新。
  每次发布版本之前需要打个git tag：git tap v1.0.1。运行npm version它也会自动的帮你打这个tag 
  提交远程：git push origin master
生成这个包当前版本的changelog
发布版本：npm publish

8.Git Commit规范和changelog生成
基础包良好的commit规范有助于我们后续维护代码
良好的git commit规范优势：
  加快code review的流程
  根据规范的git commit的元数据可以快速的生成changelog文档，这样就避免手动的编写changelog消耗的时间。
  后续维护者可以知道feature被修改的原因
技术方案
  git commit提交格式
    统一团队git commit日志标准，便于后续代码review和版本发布
    使用angular的git commit日志作为基本规范
      提交类型限制为：feat,fix,docs,style,refactor,pref,test,chore,revert等
      提交信息分为两部分，标题（首字母不大写，末尾不要标点）、主体内容（正常的描述信息即可）
    日志提交时友好的类型选择提示
      commitize工具
    不符合要求格式的日志拒绝提交的保障机制
      使用vilidate-commit-msg工具
      需要同时在客户端、git server hook做
    统一changelog文档信息生成
      使用conventional-changelog-cli工具
提交格式要求
<type>(<scope>): <subject>
<BLANK LINE>
<body>
<BLANK LINE>
<footer>
格式说明如下：
共有三块内容：commit的头部，body内容，提交的尾部
  头部：
    type: 代表某次提交的类型
      feat: 新增特性
      fix: 修改bug
      docs: 文档修改
      style: 代码格式修改，空格、缩进、逗号等，不改变代码逻辑
      refactor: 代码重构，没有增加新功能feature或修复bug
      pref: 优化相关，如性能提升，体验优化等
      test: 测试用例修改，包括单元测试，集成测试等
      chore: 改变构建流程，或增加依赖库、工具等
      revert: 回滚到上一个版本
    scope: 作用域, commit影响的范围, 比如: route, component, utils, build...
    subject: commit的概述, 目的的简短描述, 建议符合 50/72 formatting
  内容：
    正常情况下写这个头部就已经符合一个标注的git commit规范的要求。不过有时候某一次提交可能影响很大，或做的事情很多，这时通过
    subject还不能很好的描述这一次提交做的事情，这时候可以在body里面分为几行去写，做了什么事情都可以详细的写在这里。
    body: commit 具体修改内容, 可以分为多行, 建议符合 50/72 formatting
  尾部：
    比如这次提交是修复了一个bug，可以贴上bug单的链接。或者修复一个issue，可以贴上issue的链接，把issue close掉。
    footer: 一些备注, 通常是 BREAKING CHANGE 或修复的 bug 的链接。
有这个规范还是不够的。
本地开发阶段增加precommit钩子
  对于git commit的信息也是需要通过一个工具来让git commit的规则能够很好的运作起来。
  安装husky
    npm i husky -D
  通过commitmsg钩子校验信息
    npm i vilidate-commit-msg conventional-changelog-cli -D
    "scripts": {
      "commitmsg": "vilidate-commit-msg",
      "changelog": "conventional-changelog -p angular -i CHANGELOG.md -s -r 0"
    }
    vilidate-commit-msg也是尊从angularjs提交规范
    每次git commit的时候，就会通过vilidate-commit-msg去检查这一次提交git的格式，如果是符合规范的，它就会允许你提交上去，
    不符合规范，就会提交失败。
    每次发布版本的时候可以运行changelog这个命令，可以很方便的生成一个changelog文档出来，这个版本信息就会全部的生成出来，包
    括两块内容，一个是bugfix，对应于fix；一个是feature，对应于feat。

9.语义化版本（Semantic Versioning）规范格式
开源项目版本信息案例（react）
  软件的版本通常由三位组成，形如：X.Y.Z
  版本是严格递增的，此处是：16.2.0 -> 16.3.0 -> 16.3.1
  在发布重要版本时，可以发布alpha，beta，rc等先行版本
遵守semver规范的优势
  semver规范是github提出来，当时也是为了解决软件开发领域里面依赖地狱的问题，主要是用来规范依赖的软件包，在日常的开发过程中，
  会依赖各种各样的依赖，这个依赖它也会依赖其他的依赖，这是就很容易形成一个依赖地狱，如果一旦依赖的版本号，没有一个很好的规范，
  很容易出现一些循环依赖，或者依赖之间会有一些冲突，尊从semver这个规范就能避免这个问题。
  优势：
    避免出现循环依赖
    依赖冲入减少
语义化版本（Semantic Versioning）规范格式
  主版本号：当你做了不兼容的API修改
  次版本号：当你做了向下兼容的功能性新增
  修订号：当你做了向下兼容的问题修复
先行版本号
  先行版本号可以作为发布正式版之前的版本，格式是在修订版本号后面加上一个连接号（-），再加上一连串以点（.）分割的标识符，标识符
  可以由英文数字和连接号（[0-9A-Za-z-]）组成。
  alpha：是内部测试版，一般不向外发布，会有很多bug。一般只有测试人员使用。
  beta：是外部小范围的测试版，这个阶段的版本会一直加入新的功能。在alhpa版之后推出。
  rc：Release Candidate，公测，系统平台上就是发行候选版本。rc版不会再加入新的功能，主要着重于除错。

第五章：webpack构建速度和体积优化策略
在webpack里面怎么分析构建速度和构建体积
1.初级分析：使用webpack内置的stats
stats：构建的统计信息
  利用webpack内置的stats对象
    它可以帮我们分析基本的一些信息，比如构建总共的时间，构建资源的大小
    package.json中使用stats
      指定输出的是一个json对象，生成一个json文件
      "scripts": {
        "build:stats": "webpack --config webpack.prod.js --json > stats.json"
      }
  node.js中使用
    const webpack = require('webpack')
    const config = require('./webpack.config.js')('production')
    webpack(config, (err, stats) => {
      if (err) {
        return console.error(err)
      }
      if (stats.hasErrors()) {
        return console.error(stats.toString('errors-only'))
      }
      console.log(stats)
    })
  这两种方式颗粒度太粗，看不出问题所在。想要分析实际的问题，比如哪个组件比较大，哪个loader耗的时间比较长，是无法很好的分析出来的。

2.速度分析：使用speed-measure-webpack-plugin
更好的分析webpack构建的速度，怎么找出构建速度问题所在。
使用speed-measure-webpack-plugin
  可以看到每个loader和插件执行耗时，就可以重点的关注耗时较长的loader或插件，针对这些做优化
  const SpeedMeatureWebpackPlugin = require('speed-measure-webpack-plugin')
  const smp = new SpeedMeatureWebpackPlugin()
  const webpackConfig = smp.wrap({
    plugins: [
      new MyPlugin(),
      new MyOtherPlugin()
    ]
  })
速度分析插件作用
  分析整个打包总耗时
  每个loader和插件的耗时情况

3.体积分析：使用webpack-bundle-analyzer
更好的分析项目打包出来的体积的问题所在
使用webpack-bundle-analyzer分析体积
  我们发现打包出来的体积很大，就可以利用这个工具来分析项目的问题出现在哪里。
  它可以把我们的项目打包出来的文件会进行一个分析，能很方便的看出体积的大小。面积越大体积越大，我们可以重点关注这些进行优化。
  const BundleAnalyzerPlugin = require('webpack-bundle-analyzer').BundleAnalyzerPlugin
  plugins: [
    new BundleAnalyzerPlugin()
  ]
  构建完成后会在8888端口展示体积大小
可以分析哪些问题
  可以很好的分析依赖的第三方模块文件的大小
  也可以分析出我们自己写的业务的组件代码图片大小，针对大的js可以做js的按需加载等优化操作。
增加babel-polyfill试验大的第三方模块的情况

4.使用高版本的webpack和Node.js
在webpack里做速度的优化
使用高版本的wepback和node.js
  在软件这一块，性能往往不是最大的问题，软件不断的迭代过程中，可以不断的提升这个性能，对于构建而言同样是适用的，所以推荐采用
  高版本的webpack和node.js。
使用webpack4：优化原因
  V8带来的优化，V8 6.0的版本带来了大量的优化，很多对原生方法的优化（for of代替forEach、Map和Set代替Object、includes代替indexOf）
  默认使用更快的md4的 hash算法
  webpacks AST可以直接从loader传递给AST，减少解析时间
  使用字符串的方法替代正则表达式
高版本的node.js对原生的js API或js的数据结构是有做一些优化的，因此推荐采用更高版本的node.js
  测试脚本
    验证高版本node.js比低版本node.js性能更快，针对相同的api、相同的代码做比较
      map-performance.js 
    includes和indexOf的性能差异
      compare-includes-indexOf.js

5.多进程/多实例构建
多进程/多实例构建：资源并行解析可选方案
  HappyPack
  thread-loader
  parallel-webpack
多进程/多实例：使用HappyPack解析资源
  原理：每次webpack解析一个模块，HappyPack会将它及它的依赖分配给worker线程中。
  每次webpack解析一个模块，一个进程webpack自身去解析这个模块。HappyPack会将这个模块进行一个划分，比如有多个模块，在
  webpack compiler run方法之后，然后到达HappyPack，它会做一些初始化，创建一个线程池，线程池会将构建任务里面的模块进行分配
  ，比如会将某个模块以及它的依赖分配给HappyPack其中的一个线程，以此类推，那么一个HappyPack的线程池可能会包括多个线程，这些
  线程会各自的处理这些模块以及它的依赖。处理完成之后，会有一个通信的过程，会将处理好的资源传输给HappyPack的主进程，完成整个构
  建的过程。
  plugins: [
    new HappyPack({
      id: 'jsx',
      threads: 4,
      loaders: ['babel-loader']
    }),
    new HappyPack({
      id: 'styles',
      threads: 2,
      loaders: ['style-loader', 'css-loader', 'less-loader']
    })
  ]
多进程/多实例：使用thread-loader解析资源
  webpack4.0原生的提供了thread-loader这个模块，它可以很好的替换HappyPack，来做多进程/多实例的工作。
  原理：跟HappyPack是差不多的。每次webpack解析一个模块，thread-loader会将它及它的依赖分配给worker线程中。
  module: {
    rules: [
      {
        test: /\.js$/,
        use: [
          {
            loader: 'thread-loader',
            options: {
              workers: 3
            }
          },
          'babel-loader'
        ]
      }
    ]
  }
  在我们的loader之前放上thread-loader，做一系列的解析，最后会通过thread-loader进行处理。

6.多进程/多实例并行压缩代码
多进程/多实例：并行压缩
上节提到在构建的时候，可以对模块的解析采用多进程多实例的方式去做。同样的，在代码解析完成之后，在做最后的代码输出之前，它有个压缩
阶段，对于代码压缩我们也是可以通过同样的思路，就是通过多进程多实例的并行的压缩代码，来达到我们优化构建速度的目的。
方法一：使用parallel-uglify-plugin插件
  plugins: [
    new ParallelUglifyPluging({
      uglifyJS: {
        output: {
          beautify: false,
          comments: false
        },
        compress: {
          warning: false,
          drop_console: true,
          collapse_vars: true,
          reduce_vars: true
        }
      }
    })
  ]
方法二：uglifyjs-webpack-plugin开启parallel参数（webpack3推荐采用的插件）（不支持es6代码的压缩）
  plugins: [
    new UglifyjsWebpackPlugin({
      uglifyOptions: {
        warnings: false,
        parse: {},
        compress: {},
        mangle: true,
        output: null,
        tiplevel: false,
        nameCache: null,
        ie8: false,
        keep_fnames: false
      },
      parallel: true
    })
  ]
方法三：terser-webpack-plugin开启parallel参数（webpack4默认使用的）（支持es6代码的压缩）
  module.exports = {
    optimization: {
      minimize: true,
      minimizer: [
        new TerserPlugin({
          parallel: true
        })
      ]
    }
  }

7.进一步分包：预编译资源模块
分包：设置Externals（第三章讲过的）
  思路：将react, react-dom基础包通过cdn引入，不打入bundle中。
  方法：使用html-webpack-externals-plugin
  缺点：一个基础库需要指定一个cdn，实际的项目中有很多包，需要引入的script标签太多 。
通过split-chunks-plugin插件分离基础包，它每次还是会对基础包进行分析。
分包来说，更好的方式就是
进一步分包：预编译资源模块
  思路：将react、react-dom、redux、react-redux基础包和业务基础包打包成一个文件。
  方法：使用webpack里面官方内置的插件DLLPlugin进行分包，DLLReferencePlugin对manifest.json引用，这个文件是对分离出来
  的包的描述。然后我们在实际的webpack配置里面可以通过DLLReferencePlugin去引用通过DLLPlugin分离出来的包，引用的时候应用
  manifest.json就可以了，引用后它就会自动的去关联DLLPlugin里面的包。
  使用DLLPlugin进行分包
    需要创建一个单独的构建配置文件，一般会命名为webpack.ddl.js，DLLPlugin也会提高打包的速度。
  使用DLLReferencePlugin引用manifest.json
    在webpack.config.js中引入
      module.exports = {
        plugins: [
          new webpack.DLLReferencePlugin({
            manifest: require('./build/library/manifest.json')
          })
        ]
      }

8.充分利用缓存提升二次构建速度
缓存
目的：提升二次构建速度
缓存思路：
  babel-loader开启缓存
  terser-webpack-plugin开启缓存
  使用cache-loader或者hard-source-webpack-plugin
    针对模块的缓存的开启
有缓存的话node_modules下面会有一个cache目录

9.缩小构建目标
缩小构建目标
  目的：尽可能的减少构建模块
  比如babel-loader不解析node_modules
    module: {
      rules: [
        {
          test: /\.js$/,
          use: 'babel-loader',
          exclude: 'node_modules'
        }
      ]
    }
减少文件搜索范围  
  优化resolve.modules配置（减少模块搜索层级）
    resolve.modules是模块解析的过程，webpack解析时，模块的查找过程和nodejs的模块查找是比较类似的，会从当前的项目找，没
    找到会去找node_modules。会依次去子目录找模块是否存在。
  优化resolve.mainFields配置
    找入口文件的时候，它会根据package.json里面的main字段查找，因为我们发布到npm的组件的package.json会遵守一定的规范，
    都会有main这个字段，我们可以设置查找的时候直接读取main这个字段，这样也减少一些不必要的分析的过程。比如package.json
    里面没有这个main，那它再去读取根项目下的index.js，没有再去找lib下面的index.js，这就是它默认的查找过程，我们这里把
    这个默认的查找过程链路做一个优化，我们只找package.json中main字段指定的入口文件。
  优化resolve.extensions配置
    模块路径的查找，比如import一个文件，没有写后缀，webpack会先去找.js，没有会找.json，默认情况下webpack只支持js和json
    的读取。extensions数组里可以再设置其他的文件，如.jsx .vue .ts等。不过这个数组里面的内容越多的话，查找消耗的时间也会
    越多，因此我们可以缩小extensions查找的范围，比如只设置查找.js，其他文件需要你写的时候写全文件后缀。避免webpack做不必要
    的查找。
  合理使用alias
    别名，简短的缩写。比如模块的路径，我们找react，它可能找了一圈，最后肯定是会找到node_modules里面去，它会经历一系列的
    查找过程，我们可以把这一系列的过程直接给它写好，告诉它比如你遇到了react，就直接从指定的这个路径去找。这个也大大的缩短
    了查找的时间。
  module.exports = {
    // 子模块的查找策略
    resolve: {
      alias: {
        'react': path.resolve(__dirname, './node_modules/react/umd/react.production.min.js'),
        'react-dom': path.resolve(__dirname, './node_modules/react-dom/umd/react-dom.production.min.js')
      },
      modules: [path.resolve(__dirname, 'node_modules')],
      extensions: ['.js'],
      mainFields: ['main']
    }
  }

10.使用Tree Shaking擦除无用的JavaScript和CSS
无用的css如何删除掉？
  PurifyCSS：遍历代码，识别已经用到的css class
  uncss：要求HTML需要通过jsdom加载，所有的样式通过PostCSS解析，通过document.querySelector来识别在html文件里面不存在的
         选择器。
在webpack中如何使用PurifyCSS？
  使用purgecss-webpack-plugin，它不能独立的去使用，而是需要提取css为一个文件后才能使用。在webpack4里面需要和
  mini-css-extract-plugin配合使用，在webpack3里面需要和extract-text-webpack-plugin配合使用。
  new PurgecssWebpackPlugin({
    paths: 
  })

11.使用webpack进行图片压缩
图片资源相对是较大的，我们可以通过在线工具手动进行图片的批量压缩。构建工具一部分的职责就是将平时我们手动完成的事做成自动化。
图片压缩
  要求：基于node库的imagemin或者tinypng API做图片压缩。
  使用：配置image-webpack-loader
imagemin的优点分析
  有很多定制的选项
  可以引入更多第三方优化插件，例如pngquant
  可以处理多种图片格式
imagemin的压缩原理
https://unsplash.com/ 无版图片库

12.使用动态Polyfill服务
构建体积优化：动态polyfill
方案
  babel-polyfill
  babel-plugin-transform-runtime
  自己写polyfill
  polyfil service
polyfil service原理
  识别ua，下发不同的polyfill
使用polyfil service
  polyfill.io官方提供的服务
    https://polyfill.io/v3/polyfill.min.js
  基于官方自建polyfill服务
    //huayang.qq.com/polyfill/v3/polyfill.min.js?unknown=polyfill&features=Promise,Map,Set
体积优化策略总结：
  Scope Hoisting
  Tree Shaking
  公共资源分离
  图片压缩
  动态polyfill

第六章：通过源代码掌握webpack打包原理
1.webpack启动过程分析
开始：从webpack命令行说起
  通过npm scripts运行webpack
    开发环境：npm run dev
    生产环境：npm run build
  通过webpack命令直接运行
    webpack entry.js bundle.js
查找webpack入口文件
  在命令行输入命令后，npm会让命令行工具进入node_modules/.bin目录，运行一个命令，如果是全局安装这个包，linux会从
  user/local/bin这个目录去找，局部安装会在当前项目目录的node_modules/.bin目录去找，查找是否存在webpack.sh或
  webpack.cmd文件。如果存在，就执行，不存在，就抛出错误。
  实际的入口文件是：node_modules/webpack/bin/webpack.js
  局部安装，想再node_modules/.bin下面有命令，必须通过package.json中的bin字段进行指定。
  因此启动的过程最终会进入到webpack.js，执行里面的代码。
分析webpack的入口文件：webpack.js
  process.exitCode = 0 // 默认exitCode是0，代表webpack运行的时候是正常的执行返回。中间报错会修改exitCode，并抛出错误。
  const runCommand = (command, args) => {} // 运行某个命令
  const isInstalled = packageName => {}; // 判断某个包是否安装
  const CLIs = []; // webpack可用的CLI：webpack-cli和webpack-command
  const installedClis = CLIs.filter(cli => cli.installed); // 判断两个cli是否安装了
  if (installedClis.length === 0) { // 根据cli安装的数量进行处理
  } else if (installedClis.length === 1) {
  } else {
  }
启动后的结果
  webpack最终找到webpack-cli(或webpack-command)这个npm包，并且执行cli

2.webpack-cli源码阅读
webpack-cli做的事情
  引入yargs，对命令行进行定制。
  分析命令行参数，对各个参数进行转换，组成编译配置项。
  引用webpack，根据配置项进行编译和构建。
从NON_COMPILATION_CMD分析出不需要编译的命令
  webpack-cli处理不需要经过编译的命令，就是不需要实例化webpack的
NON_COMPILATION_ARGS
  webpack-cli提供的不需要编译的命令
  const NON_COMPILATION_ARGS = [
    "init",              // 创建一份webpack配置文件
    "migrate",           // 运行webpack版本迁移
    "add",               // 往webpack配置文件中增加属性
    "remove",            // 往webpack配置文件中删除属性
    "serve",             // 运行webpack-serve
    "generate-loader",   // 生成webpack loader代码
    "generate-plugin",   // 生成webpack plugin代码
    "info"               // 返回与本地环境相关的一些信息
  ];
命令行工具包yargs介绍
  提供命令和分组参数
  动态生成help帮助信息
webpack-cli使用args分析
  参数分组（config/config-args.js），将命令划分为9类：
    Config options: 配置相关参数（文件名称，运行环境等）
    Basic options: 基础参数（entry设置、debug模式设置、watch监听设置、devtool设置）
    Module options: 模块参数，给loader设置扩展
    Output options: 输出设置（输出路径，输出文件名称）
    Advanced options: 高级用法（记录设置、缓存设置、监听频率、bail等）
    Resolving options: 解析参数（alias和解析的文件后缀设置）
    Optimizing options: 优化参数
    Stats options: 统计参数
    options: 通用参数（帮助命令、版本信息等）
options变量
  将命令行或webpack.config.js配置文件的配置解析出来组装成为webpack可识别的配置到options里面。
processOptions(options)函数
  outputOptions根options类似
实例化一个webpack
  webpack = require('webpack')
  compiler = webpack(options)
  new Plugin({
    option: true
  }).apply(compiler)
webpack-cli执行结果
  webpack-cli对配置文件和命令行参数进行转换，最终生成配置选项参数options和outputOptions。
  最终会根据配置参数实例化webpack对象，然后根据一些参数，如有没有--watch，有的话通过监听的方式去运行webpack，
  compiler.watch()没有的话直接运行webpack，compiler.run()。最后执行整个构建流程。

3.Tapable插件架构与Hooks设计
webpack的本质
  webpack可以将其理解成一种基于事件流的编程范例，一系列的插件运行。内部是由各种各样的插件，插件会监听compiler和compilation
  上面定义的关键的事件节点。
webpack里最核心的对象compiler和compilation都是继承自Tapable
  class Compiler extends Tapable {
    //...
  }
  class Compilation extends Tapable {
    //...
  }
Tapable是什么
  Tapable是一个类似于node.js的EventEmitter的库，主要是控制钩子函数的发布与订阅，控制着webpack的插件系统。
  Tapable库暴露了很多Hook(钩子)类，为插件提供挂载的钩子。每个钩子代表一个关键的事件节点，在插件中监听钩子，在不同的阶段做不
  同的事情。
  钩子：两类，同步钩子和异步钩子
  const {
    SyncHook,                   // 同步钩子
    SyncBailHook,               // 同步熔断钩子，遇到return直接返回
    SyncWaterfallHook,          // 同步流水钩子，执行结果可以传递给下一个插件
    SyncLoopHook,               // 同步循环钩子
    AsyncParallelHook,          // 异步并发钩子
    AsyncParallelBailHook,      // 异步并发熔断钩子
    AsyncSeriesHook,            // 异步串行钩子 
    AsyncSeriesBailHook,        // 异步串行熔断钩子
    AsyncSeriesWaterfallHook,   // 异步串行流水钩子
  } = require("tapable")
  Tapable hooks类型
    Hook           所有钩子的后缀
    Waterfall      同步方法，它会传值给下一个函数
    Bail           熔断：当函数有任何返回值，就会在当前执行函数停止
    Loop           监听函数返回true表示继续循环，返回undefined表示结束循环
    Sync           同步方法
    AsyncSeries    异步串行钩子
    AsyncParallel  异步并行执行钩子
  Tapable的使用 - new Hook新建钩子
    Tapable暴露出来的都是类方法，new一个类方法获得我们需要的钩子
    class接受数组参数options，非必传。类方法会根据传参，接受同样数量的参数。
    const hook1 = new SyncHook(['arg1', 'arg2', 'arg3'])
  Tapable的使用 - 钩子的绑定与执行
    Tapable提供了同步&异步绑定钩子的方法，并且它们都有绑定事件和执行事件对应的方法。
    Async*                           Sync*                  
    绑定：tapAsync/tapPromise/tap     绑定：tap
    执行：callAsync/promise           执行：call
  Tapable的使用 - hook基本用法示例
    const hook1 = new SyncHook(['arg1', 'arg2', 'arg3'])
    // 绑定事件到webpack事件流
    hook1.tap('hook1', (arg1, arg2, arg3) => {console.log(arg1, arg2, arg3)})
    // 执行绑定的事件
    hook1.call(1, 2, 3)
  Tapable的使用 - 实际例子演示
    定义一个Car方法，在内部hooks上新建钩子。分别是同步钩子accelerate、break（accelerate接收一个参数）、异步钩子
    calculateRoutes。
    使用钩子对应的绑定和执行方法。
    calculateRoutes使用tapPromise可以返回一个promise对象。

4.Tapable是如何和webpack进行关联起来的？
compiler和compilation上面做hooks的调用。
Tapable是事件的机制，webpack插件机制都是基于Tapable的钩子。
插件有个apply方法，接收一个compiler参数。
插件上面做事件的监听。

5.webpack流程篇：准备阶段
6.webpack流程篇：模块构建和chunk生成阶段
7.webpack流程篇：文件生成
8.动手编写一个简易的webpack(上)
9.动手编写一个简易的webpack(下)

第七章：编写loader和插件

第八章：React全家桶和webpack开发商城项目
